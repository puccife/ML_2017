{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "**Finding the Higgs Boson**\n",
    "![Higgs Boson](https://home.cern/sites/home.web.cern.ch/files/styles/medium/public/image/featured/2014/01/higgs_event_display_1.jpg?itok=0zdD0QEr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libs and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/train.csv'\n",
    "test_path = './data/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams, will be used with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iter = 10000\n",
    "threshold = 1e-8\n",
    "gamma = 0.01\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, x, ids = load_csv_data(train_path)\n",
    "ytest, xtest, idstest = load_csv_data(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing column features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_feature_to_delete = [15,18,20,25,28]\n",
    "x = np.delete(x, columns_feature_to_delete, 1)\n",
    "xtest = np.delete(xtest, columns_feature_to_delete, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[np.where(x == -999)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, mean_x, std_x = standardize(x)\n",
    "xtest, mean_xtest, std_xtest = standardize(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.nan_to_num(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_by_newton_method(y, tx, w):\n",
    "    \"\"\"\n",
    "    Do one step on Newton's method.\n",
    "    return the loss and updated w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # return loss, gradient and hessian: TODO\n",
    "    # ***************************************************\n",
    "    print('here it is')\n",
    "    loss, gradient, hessian = logistic_regression(y,tx,w)\n",
    "    \n",
    "    #raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # update w: TODO\n",
    "    # ***************************************************\n",
    "    print('here it is')\n",
    "    termine = np.linalg.solve(hessian,gradient)\n",
    "    w = w-termine\n",
    "    \n",
    "    #raise NotImplementedError\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression_newton_method_demo(y, x):\n",
    "    # init parameters\n",
    "    max_iter = 100\n",
    "    threshold = 1e-8\n",
    "    lambda_ = 0.01\n",
    "    losses = []\n",
    "\n",
    "    print('Here')\n",
    "    # build tx\n",
    "    w = np.zeros((x.shape[1], 1))\n",
    "    print(w.shape)\n",
    "    print('now here')\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iter):\n",
    "        print('boom')\n",
    "        # get loss and update w.\n",
    "        loss, w = learning_by_newton_method(y, x, w)\n",
    "        print('boooooom')\n",
    "        # log info\n",
    "        if iter % 1 == 0:\n",
    "            print(\"Current iteration={i}, the loss={l}\".format(i=iter, l=loss))\n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
    "            break\n",
    "    # visualization\n",
    "    visualization(y, x, mean_x, std_x, w, \"classification_by_logistic_regression_newton_method\")\n",
    "    print(\"loss={l}\".format(l=calculate_loss(y, tx, w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "degree = 1\n",
    "px_train = build_poly(degree=degree,x=x)\n",
    "px_test = build_poly(degree=degree,x=xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "Here\n",
      "(26, 1)\n",
      "now here\n",
      "boom\n",
      "here it is\n",
      "hessian\n",
      "cussomak\n",
      "cussomak\n",
      "cussomak\n",
      "cussomak\n",
      "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.06833197  0.55250482  3.19515553 ...,  0.31931645 -0.84532397\n",
      "   0.66533608]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.4125105  -0.27381996 -0.29396985 ..., -0.31701723 -0.74543941\n",
      "  -0.74543941]]\n",
      "[[ 0.25  0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.25  0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.25 ...,  0.    0.    0.  ]\n",
      " ..., \n",
      " [ 0.    0.    0.   ...,  0.25  0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.25  0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.25]]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "logistic_regression_newton_method_demo(y, px_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,2,3])\n",
    "v2 = np.matrix([1,2,3])\n",
    "np.reshape(v2, (3,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 151)\n",
      "(568238, 151)\n"
     ]
    }
   ],
   "source": [
    "print(px_train.shape)\n",
    "print(px_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws = ridge_regression(lambda_=0.00067233575365, tx=px_train, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = predict_labels(ws, px_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(idstest, y_pred, 'prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After lambdas iteration, the best lambda is : 0.000923670857187 for k-fold : 0 with best loss = 0.32320282507\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 1 with best loss = 0.318268149501\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 2 with best loss = 0.318268149501\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 3 with best loss = 0.318268149501\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 4 with best loss = 0.318268149501\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 5 with best loss = 0.318268149501\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 6 with best loss = 0.318268149501\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 7 with best loss = 0.318268149501\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 8 with best loss = 0.318268149501\n",
      "After lambdas iteration, the best lambda is : 0.00067233575365 for k-fold : 9 with best loss = 0.318268149501\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEaCAYAAAASSuyNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1080d2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 1\n",
    "degree = 6\n",
    "k_fold = 10\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "best_loss = 999\n",
    "for k in range(k_fold):\n",
    "    temp_tr = []\n",
    "    temp_te = []\n",
    "    best_test_ws = []\n",
    "    for lambda_ in lambdas:\n",
    "        tr_loss, te_loss, ws = cross_validation(y, x, k_indices, k, lambda_, degree)\n",
    "        if(te_loss < best_loss):\n",
    "            best_loss = te_loss\n",
    "            best_lambda = lambda_\n",
    "        temp_tr.append(tr_loss)\n",
    "        temp_te.append(te_loss)\n",
    "        # print(\"Lambda = \" + str(lambda_) + \" tr_loss = \" + str(tr_loss) + \" te_loss = \" + str(te_loss))\n",
    "    print(\"After lambdas iteration, the best lambda is : \" + str(best_lambda) + \" for k-fold : \" + str(k) + \" with best loss = \" + str(best_loss))\n",
    "    best_test_ws.append(lambda_)\n",
    "    rmse_tr.append(temp_tr)\n",
    "    rmse_te.append(temp_te)\n",
    "\n",
    "rmse_tr = np.matrix(rmse_tr)\n",
    "rmse_tr = np.mean(rmse_tr, axis=0)\n",
    "rmse_tr = np.reshape(rmse_tr, (len(lambdas),-1))\n",
    "rmse_te = np.matrix(rmse_te)\n",
    "rmse_te = np.mean(rmse_te, axis=0)\n",
    "rmse_te = np.reshape(rmse_te, (len(lambdas),-1))\n",
    "\n",
    "cross_validation_visualization(lambdas, rmse_tr, rmse_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
